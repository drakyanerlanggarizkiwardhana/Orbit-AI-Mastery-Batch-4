{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Backpropagation-ANN-Fix.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Program back propagation ini adalah code from scratch, setiap cell code di upgrade misalnya di cell pertama dipakai untuk import library, lalu cell berikutnya ada contoh dataset untuk kasus XOR, lalu ada dataset lebih banyak dengan 12 pola data. \n",
        "\n",
        "Dengan beberapa dataset itu silakan bandingkan hasilnya algoritma menggunakan learning rate, penambahan momentum, diskusikan dengan coach/student kalian."
      ],
      "metadata": {
        "id": "yhEtj596PQJp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library numpy yang digunakan"
      ],
      "metadata": {
        "id": "CPdiUqtOj02L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Packages\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "print(\"Versi numpy yang digunakan adalah\", np.__version__)"
      ],
      "metadata": {
        "id": "LA0C_jjWj4rN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menambahkan set data dengan kasus XOR"
      ],
      "metadata": {
        "id": "WT3tSNNwanAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set data 1 kasus XOR"
      ],
      "metadata": {
        "id": "s0zXv3vlc1Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lvInput = np.array([[0, 0], [1, 1], [0, 1], [1, 0]]) # Dari data input x adalah 2\n",
        "lvTarget = np.array([[0.05], [0.05], [0.95], [0.95]]) # Dari data target T adalah 1"
      ],
      "metadata": {
        "id": "46BPMl3janen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set data 2\n",
        "\n",
        "- Jika pakai dataset ini isi nilai Input_x menjadi 12 sesuai dengan jumlah pola 1 "
      ],
      "metadata": {
        "id": "S9SHGHyIc_g3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lvInput = np.array ([[0.1614, 0.1394, 0.1171, 0.1070, 0.1342, 0.1738, 0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678],  #pola 1\n",
        "                         [0.1394, 0.1171, 0.1070, 0.1342, 0.1738, 0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439],  #pola 2\n",
        "                         [0.1171, 0.1070, 0.1342, 0.1738, 0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249],  #pola 3\n",
        "                         [0.1070, 0.1342, 0.1738, 0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013],  #pola 4\n",
        "                         [0.1342, 0.1738, 0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1],     #pola 5\n",
        "                         [0.1738, 0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179],  #pola 6\n",
        "                         [0.4204, 0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179, 0.3678],  #pola 7\n",
        "                         [0.6896, 0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179, 0.3678, 0.4838],  #pola 8\n",
        "                         [0.6363, 0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179, 0.3678, 0.4838, 0.9],     #pola 9\n",
        "                         [0.3657, 0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179, 0.3678, 0.4838, 0.9,    0.7017],  #pola 10\n",
        "                         [0.2266, 0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179, 0.3678, 0.4838, 0.9,    0.7017, 0.5189],  #pola 11\n",
        "                         [0.1678, 0.1439, 0.1249, 0.1013, 0.1,    0.1179, 0.3678, 0.4838, 0.9,    0.7017, 0.5189, 0.2394]]) #pola 12\n",
        "    \n",
        "lvTarget = np.array ([[0.1439], [0.1249], [0.1013], [0.1], [0.1179], [0.3678], [0.4838], [0.9], [0.7017], [0.5189], [0.2394], [0.1837]])"
      ],
      "metadata": {
        "id": "kk4sPa45dCP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menambhakan layer input dan layer output\n"
      ],
      "metadata": {
        "id": "UPlDHKlgZylo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Input_x = 12 # Nilainya sesuaikan dengan matrik Input misalnya pada contoh adalah 2\n",
        "Output_y = 1 # Nilainya sesuaikan dengan matrik Output target misalnya pada contoh adalah 1"
      ],
      "metadata": {
        "id": "QlQ7nNfMZ7D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Membangun class Back Propagation dan membuat input layer, hidden layer, dan output layer. Tapi, kita belum fokus untuk membuat algoritma feed forward dan algoritma back propagation."
      ],
      "metadata": {
        "id": "gHDLBdchyX-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class BackPropagationNetwork:\n",
        "    \"\"\"A back-propagation network\"\"\"\n",
        "\n",
        "    # Class members\n",
        "    layerCount = 0\n",
        "    shape = None\n",
        "    weights = []\n",
        "\n",
        "    # Class methods\n",
        "    def __init__(self, layerSize):\n",
        "        \"\"\"Initialize the network\"\"\"\n",
        "\n",
        "        # Layer info\n",
        "        self.layerCount = len(layerSize) - 1\n",
        "        self.shape = layerSize\n",
        "\n",
        "        # Input/Output data from last run\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "\n",
        "        # Create the weight arrays\n",
        "        for (l1, l2) in zip(layerSize[:-1], layerSize[1:]):\n",
        "            self.weights.append(np.random.normal(scale=0.1, size = (l2, l1+1)))\n",
        "\n",
        "\n",
        "# If run as script, create a test object\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    \"\"\"\n",
        "    Keterangan:\n",
        "      =====bpn = BackPropagationNetwork((Input_x, 2, Output_y))=====\n",
        "    - Input_x di input nilainya sesuai dengan banyaknya dimensi di pola 1,/\n",
        "      misalnya pada data berikut [[0, 0], [1, 1], [0, 1], [1, 0]], karena pola pertama ada 2, maka nilianya kita input juga 2,\\\n",
        "      jadi input_x = 2\n",
        "    - Nilai 2 antara Input_x dan Output_y itu adalah hidden layer, misalnya kita pakai 2, dan bisa di ganti sesui kebutuhan,\\\n",
        "      lalu dapat juka di buat menjadi 2-3-4 hidden layer misalnya, (Input_x, 15, 10, 3, Output_y)\n",
        "      \n",
        "    \"\"\"\n",
        "    bpn = BackPropagationNetwork((Input_x, 2, Output_y))\n",
        "    print(bpn.shape)\n",
        "    print(bpn.weights)\n",
        "\n"
      ],
      "metadata": {
        "id": "yyCpFsUUvJfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menambahkan algoritma feed forward dan fungsi aktivasi sigmoid"
      ],
      "metadata": {
        "id": "qESNZWH9yexJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Fungsi Aktivasi Sigmoid"
      ],
      "metadata": {
        "id": "PPJt9TFtUqbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "js4kx5SwUvqK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class BackPropagationNetwork:\n",
        "    \"\"\"A back-propagation network\"\"\"\n",
        "\n",
        "    # Class members\n",
        "    layerCount = 0\n",
        "    shape = None\n",
        "    weights = []\n",
        "\n",
        "    # Class methods\n",
        "    def __init__(self, layerSize):\n",
        "        \"\"\"Initialize the network\"\"\"\n",
        "\n",
        "        # Layer info\n",
        "        self.layerCount = len(layerSize) - 1\n",
        "        self.shape = layerSize\n",
        "\n",
        "        # Input/Output data from last run\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "\n",
        "        # Create the weight arrays\n",
        "        for (l1, l2) in zip(layerSize[:-1], layerSize[1:]):\n",
        "            self.weights.append(np.random.normal(scale=0.01, size = (l2, l1+1)))\n",
        "\n",
        "    \n",
        "    \n",
        "    #Algoritma Feed Forward \n",
        "      \n",
        "    def forwardProc(self, input):\n",
        "        \"\"\"Run the network based on the input data\"\"\"\n",
        "    \n",
        "        lnCases = input.shape[0]\n",
        "\n",
        "        # Clear out the previous intermediate value lists\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "\n",
        "        # Run it!\n",
        "        for index in range(self.layerCount):\n",
        "            # Determine layer input\n",
        "            if index == 0:\n",
        "                layerInput = self.weights[0].dot(np.vstack([input.T, np.ones([1, lnCases])])) # \n",
        "                # refrensi vstack: https://numpy.org/doc/stable/reference/generated/numpy.vstack.html\n",
        "                # .T adalah array transpose, refrensi: https://docs.scipy.org/doc/numpy-1.5.x/reference/generated/numpy.ndarray.T.html#numpy.ndarray.T\n",
        "            else:\n",
        "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1], np.ones([1, lnCases])]))\n",
        "\n",
        "            self._layerInput.append(layerInput)\n",
        "            self._layerOutput.append(self.sgm(layerInput))\n",
        "\n",
        "        return self._layerOutput[-1].T\n",
        "    \n",
        "    # Transfer functions\n",
        "    def sgm(self, x, Derivative=False):\n",
        "        if not Derivative:\n",
        "            return 1 / (1+np.exp(-x))\n",
        "        else:\n",
        "            out = self.sgm(x)\n",
        "            return out*(1-out)\n",
        "\n",
        "\n",
        "\n",
        "# If run as script, create a test object\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    \"\"\"\n",
        "    Keterangan:\n",
        "      =====bpn = BackPropagationNetwork((Input_x, 2, Output_y))=====\n",
        "    - Input_x di input nilainya sesuai dengan banyaknya dimensi di pola 1,/\n",
        "      misalnya pada data berikut [[0, 0], [1, 1], [0, 1], [1, 0]], karena pola pertama ada 2, maka nilianya kita input juga 2,\\\n",
        "      jadi input_x = 2\n",
        "    - Nilai 2 antara Input_x dan Output_y itu adalah hidden layer, misalnya kita pakai 2, dan bisa di ganti sesui kebutuhan,\\\n",
        "      lalu dapat juka di buat menjadi 2-3-4 hidden layer misalnya, (Input_x, 15, 10, 3, Output_y)\n",
        "      \n",
        "    \"\"\"\n",
        "    bpn = BackPropagationNetwork((Input_x, 2, Output_y))\n",
        "    print(bpn.shape)\n",
        "    print(bpn.weights)\n",
        "\n",
        "    # lvInput = np.array([[0, 0], [1, 1], [-1, 0.5]])\n",
        "    lvOutput = bpn.forwardProc(lvInput)\n",
        "\n",
        "    print(\"Input: {0}\\nOutput: {1}\".format(lvInput, lvOutput))"
      ],
      "metadata": {
        "id": "cYrYixpeyajf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menambahkan train epoch, perbaikan error (backpropagation) dan learning rate (eta = η)"
      ],
      "metadata": {
        "id": "kW8fEdlRwmK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.core.numeric import ones\n",
        "\n",
        "class BackPropagationNetwork:\n",
        "    \"\"\"A back-propagation network\"\"\"\n",
        "\n",
        "    # Class members\n",
        "    layerCount = 0\n",
        "    shape = None\n",
        "    weights = []\n",
        "\n",
        "    # Class methods\n",
        "    def __init__(self, layerSize):\n",
        "        \"\"\"Initialize the network\"\"\"\n",
        "\n",
        "        # Layer info\n",
        "        self.layerCount = len(layerSize) - 1\n",
        "        self.shape = layerSize\n",
        "\n",
        "        # Input/Output data from last run\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "\n",
        "        # Create the weight arrays\n",
        "        for (l1, l2) in zip(layerSize[:-1], layerSize[1:]):\n",
        "            self.weights.append(np.random.normal(scale=0.1, size = (l2, l1+1)))\n",
        "\n",
        "    \n",
        "    # Run method\n",
        "    def forwardProc(self, input):\n",
        "        \"\"\"Run the network based on the input data\"\"\"\n",
        "    \n",
        "        lnCases = input.shape[0]\n",
        "\n",
        "        # Clear out the previous intermediate value lists\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "\n",
        "        # Run it!\n",
        "        for index in range(self.layerCount):\n",
        "            # Determine layer input\n",
        "            if index == 0:\n",
        "                layerInput = self.weights[0].dot(np.vstack([input.T, np.ones([1, lnCases])])) # \n",
        "                # refrensi vstack: https://numpy.org/doc/stable/reference/generated/numpy.vstack.html\n",
        "                # .T adalah array transpose, refrensi: https://docs.scipy.org/doc/numpy-1.5.x/reference/generated/numpy.ndarray.T.html#numpy.ndarray.T\n",
        "            else:\n",
        "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1], np.ones([1, lnCases])]))\n",
        "\n",
        "            self._layerInput.append(layerInput)\n",
        "            self._layerOutput.append(self.sgm(layerInput))\n",
        "\n",
        "        return self._layerOutput[-1].T\n",
        "    \n",
        "    # Train Epoch Method\n",
        "    def TrainEpoch(self, input, target, trainingRate = 0.2):\n",
        "        \"\"\"This method trains the network for one epoch\"\"\"\n",
        "\n",
        "        delta = []\n",
        "        lnCases = input.shape[0]\n",
        "\n",
        "        # First run the network\n",
        "        self.forwardProc(input)\n",
        "\n",
        "        # Calculate our deltas\n",
        "        for index in reversed(range(self.layerCount)):\n",
        "            if index == self.layerCount - 1:\n",
        "                # Compare to the target values\n",
        "                output_delta = self._layerOutput[index] - target.T\n",
        "                error = np.sum(output_delta**2)\n",
        "                delta.append(output_delta * self.sgm(self._layerInput[index], True))\n",
        "            else:\n",
        "                # Compare to the following layer's delta\n",
        "                delta_pullback = self.weights[index + 1].T.dot(delta[-1])\n",
        "                delta.append(delta_pullback[:-1, :] * self.sgm(self._layerInput[index], True))\n",
        "\n",
        "        # Compute weight deltas\n",
        "        for index in range(self.layerCount):\n",
        "            delta_index = self.layerCount - 1 - index\n",
        "\n",
        "            if index == 0:\n",
        "                layerOutput = np.vstack([input.T, np.ones([1, lnCases])])\n",
        "            else:\n",
        "                layerOutput = np.vstack([self._layerOutput[index - 1], np.ones([1, self._layerOutput[index - 1].shape[1]])])\n",
        "\n",
        "            weightDelta = np.sum(\\\n",
        "                                 layerOutput[None,:,:].transpose(2, 0, 1) * delta[delta_index][None,:,:].transpose(2, 1, 0)\\\n",
        "                                 , axis = 0)\n",
        "            \n",
        "            self.weights[index] -= trainingRate * weightDelta\n",
        "\n",
        "        return error\n",
        "    \n",
        "    # Transfer functions\n",
        "    def sgm(self, x, Derivative=False):\n",
        "        if not Derivative:\n",
        "            return 1 / (1+np.exp(-x))\n",
        "        else:\n",
        "            out = self.sgm(x)\n",
        "            return out*(1-out)\n",
        "\n",
        "\n",
        "\n",
        "# If run as script, create a test object\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    \"\"\"\n",
        "    Keterangan:\n",
        "      =====bpn = BackPropagationNetwork((Input_x, 2, Output_y))=====\n",
        "    - Input_x di input nilainya sesuai dengan banyaknya dimensi di pola 1,/\n",
        "      misalnya pada data berikut [[0, 0], [1, 1], [0, 1], [1, 0]], karena pola pertama ada 2, maka nilianya kita input juga 2,\\\n",
        "      jadi input_x = 2\n",
        "    - Nilai 2 antara Input_x dan Output_y itu adalah hidden layer, misalnya kita pakai 2, dan bisa di ganti sesui kebutuhan,\\\n",
        "      lalu dapat juka di buat menjadi 2-3-4 hidden layer misalnya, (Input_x, 15, 10, 3, Output_y)\n",
        "      \n",
        "    \"\"\"\n",
        "    bpn = BackPropagationNetwork((12, 5, 2, 1))\n",
        "    print(bpn.shape)\n",
        "    print(bpn.weights)\n",
        "\n",
        "    #lvInput = np.array([[0, 0], [1, 1], [0, 1], [1, 0]])\n",
        "    #lvTarget = np.array([[0.05], [0.05], [0.95], [0.95]])\n",
        "    \n",
        "    lnMax = 1000000\n",
        "    lnErr = 1e-5\n",
        "    for i in range(lnMax + 1):\n",
        "        err = bpn.TrainEpoch(lvInput, lvTarget)\n",
        "        if i % 2500 == 0:\n",
        "            print(\"Iteration {0}\\tError: {1:0.6f}\".format(i, err))\n",
        "        if err <= lnErr:\n",
        "            print(\"Minimum error reached at iteration {0}\".format(i))\n",
        "            break\n",
        "    \n",
        "    lvOutput = bpn.forwardProc(lvInput)\n",
        "    print(\"Input: {0}\\nOutput: {1}\".format(lvInput, lvOutput))\n"
      ],
      "metadata": {
        "id": "Wt450V0VwuyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Menambahkan momentum (alpha = α)\n",
        "\n",
        "- Tujuan menambhakan momentum adalah untuk menghindari perubahan bobot yang mencolok akibat adanya data yang sangat berbeda dengan yang lain (outlier) sehingga mempercepat tercapai proses konvergensinya."
      ],
      "metadata": {
        "id": "ZiEsUQl1S5jD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from numpy.core.numeric import ones\n",
        "import numpy as np\n",
        "\n",
        "class BackPropagationNetwork:\n",
        "    \"\"\"A back-propagation network\"\"\"\n",
        "\n",
        "    # Class members\n",
        "    layerCount = 0\n",
        "    shape = None\n",
        "    weights = []\n",
        "\n",
        "    # Class methods\n",
        "    def __init__(self, layerSize):\n",
        "        \"\"\"Initialize the network\"\"\"\n",
        "\n",
        "        # Layer info\n",
        "        self.layerCount = len(layerSize) - 1\n",
        "        self.shape = layerSize\n",
        "\n",
        "        # Data from last run\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "        self._previousWeightDelta = []\n",
        "\n",
        "        # Create the weight arrays\n",
        "        for (l1, l2) in zip(layerSize[:-1], layerSize[1:]):\n",
        "            self.weights.append(np.random.normal(scale=0.1, size = (l2, l1+1)))\n",
        "            self._previousWeightDelta.append(np.zeros((l2, l1+1)))\n",
        "    \n",
        "    # forward method\n",
        "    def forwardProc(self, input):\n",
        "        \"\"\"Run the network based on the input data\"\"\"\n",
        "    \n",
        "        lnCases = input.shape[0]\n",
        "\n",
        "        # Clear out the previous intermediate value lists\n",
        "        self._layerInput = []\n",
        "        self._layerOutput = []\n",
        "\n",
        "        # Run it!\n",
        "        for index in range(self.layerCount):\n",
        "            # Determine layer input\n",
        "            if index == 0:\n",
        "                layerInput = self.weights[0].dot(np.vstack([input.T, np.ones([1, lnCases])])) # \n",
        "                # refrensi vstack: https://numpy.org/doc/stable/reference/generated/numpy.vstack.html\n",
        "                # .T adalah array transpose, refrensi: https://docs.scipy.org/doc/numpy-1.5.x/reference/generated/numpy.ndarray.T.html#numpy.ndarray.T\n",
        "            else:\n",
        "                layerInput = self.weights[index].dot(np.vstack([self._layerOutput[-1], np.ones([1, lnCases])]))\n",
        "\n",
        "            self._layerInput.append(layerInput)\n",
        "            self._layerOutput.append(self.sgm(layerInput))\n",
        "\n",
        "        return self._layerOutput[-1].T\n",
        "    \n",
        "    # Train Epoch Method\n",
        "    def TrainEpoch(self, input, target, trainingRate = 0.2, momentum = 0.5):\n",
        "        \"\"\"This method trains the network for one epoch\"\"\"\n",
        "\n",
        "        delta = []\n",
        "        lnCases = input.shape[0]\n",
        "\n",
        "        # First run the network\n",
        "        self.forwardProc(input)\n",
        "\n",
        "        # Calculate our deltas\n",
        "        for index in reversed(range(self.layerCount)):\n",
        "            if index == self.layerCount - 1:\n",
        "                # Compare to the target values\n",
        "                output_delta = self._layerOutput[index] - target.T\n",
        "                error = np.sum(output_delta**2)\n",
        "                delta.append(output_delta * self.sgm(self._layerInput[index], True))\n",
        "            else:\n",
        "                # Compare to the following layer's delta\n",
        "                delta_pullback = self.weights[index + 1].T.dot(delta[-1])\n",
        "                delta.append(delta_pullback[:-1, :] * self.sgm(self._layerInput[index], True))\n",
        "\n",
        "        # Compute weight deltas\n",
        "        for index in range(self.layerCount):\n",
        "            delta_index = self.layerCount - 1 - index\n",
        "\n",
        "            if index == 0:\n",
        "                layerOutput = np.vstack([input.T, np.ones([1, lnCases])])\n",
        "            else:\n",
        "                layerOutput = np.vstack([self._layerOutput[index - 1], np.ones([1, self._layerOutput[index - 1].shape[1]])])\n",
        "\n",
        "            curweightDelta = np.sum(\\\n",
        "                                 layerOutput[None,:,:].transpose(2, 0, 1) * delta[delta_index][None,:,:].transpose(2, 1, 0)\\\n",
        "                                 , axis = 0)\n",
        "                                 \n",
        "            weightDelta = trainingRate * curweightDelta + momentum * self._previousWeightDelta[index]\n",
        "            \n",
        "            self.weights[index] -= weightDelta\n",
        "\n",
        "            self._previousWeightDelta[index] = weightDelta\n",
        "\n",
        "        return error\n",
        "    \n",
        "    # Transfer functions\n",
        "    def sgm(self, x, Derivative=False):\n",
        "        if not Derivative:\n",
        "            return 1 / (1+np.exp(-x))\n",
        "        else:\n",
        "            out = self.sgm(x)\n",
        "            return out*(1-out)\n",
        "\n",
        "    \n",
        "# If run as script, create a test object\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    \"\"\"\n",
        "    Keterangan:\n",
        "      =====bpn = BackPropagationNetwork((Input_x, 2, Output_y))=====\n",
        "    - Input_x di input nilainya sesuai dengan banyaknya dimensi di pola 1,/\n",
        "      misalnya pada data berikut [[0, 0], [1, 1], [0, 1], [1, 0]], karena pola pertama ada 2, maka nilianya kita input juga 2,\\\n",
        "      jadi input_x = 2\n",
        "    - Nilai 2 antara Input_x dan Output_y itu adalah hidden layer, misalnya kita pakai 2, dan bisa di ganti sesui kebutuhan,\\\n",
        "      lalu dapat juka di buat menjadi 2-3-4 hidden layer misalnya, (Input_x, 15, 10, 3, Output_y)\n",
        "      \n",
        "    \"\"\"\n",
        "    bpn = BackPropagationNetwork((3, 50, 7, 2, 1))\n",
        "    print(bpn.shape)\n",
        "    print(bpn.weights)\n",
        "\n",
        "    #lvInput2 = np.array([[0, 0,], [1, 1], [0, 1], [1, 0]])\n",
        "    #lvTarget2 = np.array([[0.05], [0.05], [0.95], [0.95]])\n",
        "\n",
        "    lvInput2 =  np.array([[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]])\n",
        "    lvTarget2 = np.array([[0.00], [1.00], [1.00], [1.00], [1.00], [1.00], [1.00], [0.00]])\n",
        "    \n",
        "    lnMax = 1000000\n",
        "    lnErr = 1e-5\n",
        "    for i in range(lnMax + 1):\n",
        "        err = bpn.TrainEpoch(lvInput2, lvTarget2, momentum = 0.7)\n",
        "        if i % 2500 == 0:\n",
        "            print(\"Iteration {0}\\tError: {1:0.6f}\".format(i, err))\n",
        "        if err <= lnErr:\n",
        "            print(\"Minimum error reached at iteration {0}\".format(i))\n",
        "            break\n",
        "    \n",
        "    lvOutput = bpn.forwardProc(lvInput2)\n",
        "    print(\"Input: {0}\\nOutput: {1}\".format(lvInput2, lvOutput))"
      ],
      "metadata": {
        "id": "xEP53yNiTJBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Lro7YS5bLULY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}